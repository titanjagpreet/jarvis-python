# ğŸš€ Jarvis AI â€“ Voice-Controlled Desktop Assistant

A modular AI-powered voice assistant for your PC.
Jarvis listens to your speech â†’ understands your natural language â†’ executes actions through tools.

This version **does NOT use wake-word detection**.
It continuously listens for commands and responds intelligently.

---

# ğŸ“š Table of Contents

* Features
* Architecture
* Project Structure
* Requirements
* Installation
* Configuration
* Usage
* How Jarvis Works
* Supported Actions
* Extending Jarvis
* Troubleshooting
* Future Upgrades

---

# âœ¨ Features

âœ” Hands-free voice commands
âœ” Natural language understanding (LLM agent)
âœ” Opens any website
âœ” Opens system apps dynamically (no hardcoding required)
âœ” Plays any song via YouTube search
âœ” Executes system commands (shutdown, restart, sleep)
âœ” Clean modular â€œtoolsâ€ system
âœ” Thread-safe TTS engine (no crashes)
âœ” Easy to extend with more abilities
âœ” Works with any LLM backend (OpenAI/Groq/OpenRouter/Gemini/local LLM)

---

# ğŸ— Architecture Overview

Jarvis has four major layers:

### **1ï¸âƒ£ Speech Layer**

* Converts your voice â†’ text
* Uses the `SpeechRecognition` library
* Microphone-based continuous listening

### **2ï¸âƒ£ Agent (LLM Reasoning Layer)**

* Takes your command
* Sends it to an AI model
* AI returns a JSON action (not text)
  Example:

```json
{
  "action": "open_website",
  "url": "https://google.com"
}
```

### **3ï¸âƒ£ Tools Layer**

Small independent modules that actually perform actions:

* browser.py
* apps.py
* system.py
* music.py

### **4ï¸âƒ£ Speaker Layer**

A **thread-safe queue-based text-to-speech** engine.

---

# ğŸ“ Project Structure

```
Jarvis/
â”‚â”€â”€ main.py                 
â”‚â”€â”€ config.py               # contains API keys
â”‚
â”‚â”€â”€ core/
â”‚   â”œâ”€â”€ listener.py         # speech recognition
â”‚   â”œâ”€â”€ speaker.py          # text-to-speech (queue)
â”‚   â”œâ”€â”€ agent.py            # LLM-based decision engine
â”‚
â”‚â”€â”€ tools/
â”‚   â”œâ”€â”€ browser.py          # open any website
â”‚   â”œâ”€â”€ apps.py             # open any system-installed app
â”‚   â”œâ”€â”€ music.py            # youtube music search
â”‚   â”œâ”€â”€ system.py           # shutdown, restart, sleep
â”‚
â””â”€â”€ data/
    â””â”€â”€ (future custom data, memory, configs)
```

---

# ğŸ§© Requirements

Install everything:

```
pip install SpeechRecognition pyttsx3 pyaudio openai
```

If PyAudio fails â†’ run:

```
pip install pipwin
pipwin install pyaudio
```

---

# âš™ Configuration

In `config.py`:

```
OPENAI_API_KEY = "your-key-here"
```

If you use Groq, Gemini, OpenRouter, or local LLM â€” we adjust this file accordingly.

---

# â–¶ï¸ Usage

Start Jarvis:

```
python main.py
```

Flow:

1. Jarvis says **â€œInitializing Jarvisâ€¦â€**
2. Starts listening immediately
3. Speak any command such as:

### Examples:

ğŸ‘‰ â€œOpen YouTubeâ€
ğŸ‘‰ â€œSearch how delta-neutral hedging worksâ€
ğŸ‘‰ â€œPlay Starboy by The Weekndâ€
ğŸ‘‰ â€œOpen VS Codeâ€
ğŸ‘‰ â€œShutdown the computerâ€
ğŸ‘‰ â€œWhat is funding arbitrage?â€

Jarvis:

* Converts speech â†’ text
* Sends to the agent
* Receives JSON describing what to do
* Executes the tool
* Speaks a response

---

# ğŸ§  How Jarvis Works (Internally)

### 1. **listener.py**

Record audio using microphone â†’ transcribe to text using Google Speech Recognition.

### 2. **agent.py**

Sends your text to the AI model with this system prompt:

```
Return ONLY JSON describing the correct action.
```

The LLM replies with:

```json
{"action": "open_app", "name": "chrome"}
```

### 3. **main.py**

Parses the JSON and calls the correct tool module.

### 4. **tools/**

Each tool performs one job:

* browser: open urls, google search, youtube search
* apps: search & launch installed executables
* system: shutdown, restart
* music: play song via YouTube search

### 5. **speaker.py**

A queue-based text-to-speech engine that **never crashes**.

---

# ğŸ”¨ Supported Actions

Jarvis currently understands these:

### âœ” **open_website**

`open google.com`, `open coinmarketcap`

### âœ” **search_google**

`search for funding rate arbitrage tutorial`

### âœ” **search_youtube**

`show me a tutorial on python bots`

### âœ” **open_app**

`open chrome`
`open vs code`

### âœ” **play_music**

`play the nights by avicii`

### âœ” **system_command**

`shutdown my pc`, `restart`, `sleep`

### âœ” **response**

For things like:

* explanations
* short answers
* small talk

---

# ğŸ§± Extending Jarvis

Add new tools easily:

Example: a file reader:

Create:

```
tools/readfile.py
```

```python
def read_file(path):
    with open(path, "r") as f:
        return f.read()
```

Add the agent support:

```json
{"action": "read_file", "path": "C:/myfile.txt"}
```

Add handler in `main.py`:

```python
elif act == "read_file":
    text = read_file(action["path"])
    speak(text)
```

Done â€” Jarvis now reads files.

You can add:

* trading bots
* screen OCR
* browser automation
* notification systems
* music players
* full GUI
* wake word (optional later)

---

# âš  Troubleshooting

### â— `openai.RateLimitError: insufficient_quota`

Your OpenAI API key has **0 credits**.
Use Groq / OpenRouter / Gemini OR add billing.

### â— â€œrun loop already startedâ€ in pyttsx3

You MUST use the queue-based TTS (included).

### â— Microphone not working

Run:

```
pipwin install pyaudio
```

### â— JSON parsing error

Your model responded with text, not JSON.
Switch to a structured-output friendly model:

* GPT-4o-mini
* Llama 3.1 via Groq
* Gemini 2.0 Flash

### Made with â¤ by Titan